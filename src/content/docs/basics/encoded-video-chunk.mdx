---
title: EncodedVideoChunk
description: EncodedVideoChunk
---

import { Tabs, TabItem } from '@astrojs/starlight/components';


The `EncodedVideoChunk` class, the other main type in WebCodecs, repesents the compressed (or "encoded") version of a single `VideoFrame`

![](/src/assets/content/basics/chunks/encoded-chunk.svg)

The `EncodedVideoChunk` contains binary data (the encoded `VideoFrame`) and some metadata, and there is a 1:1 correspondence between `EncodedVideoChunk` and `VideoFrame` objects - if you encode 100 `VideoFrame` objects, you should expect 100 `EncodedVideoChunk` objects from the encoder.

Unlike a `VideoFrame`, an `EncodedVideoChunk` objects can't be directly rendered or displayed because the data is enocoded,but they can be directly read from, or written to video files (via [muxing](../muxing)).



### Compession, not muxing

<mark>EncodedVideoChunks are not by themselves video files </mark>. 

You can not just encode a bunch of video frames, store the chunks in a blob and call it a day.


```typescript
// This will not work!
async function encodeVideo(frames: VideoFrame[]){
  const chunks = <EncodedVideoChunk[]>await encodeFrames(<VideoFrame[]> frames);
  return new Blob(chunks, {type: "video/mp4"}); //Not how this works
}
```

If you want to write your encoded video chunks to a video file, that requires an additional step called [muxing](../muxing), there are [libraries](https://mediabunny.dev/) that do this for you, we'll get to those in the next section.


For now, keep in mind that WebCodecs focuses on just on codecs, and [codecs means compression](../../intro/what-are-codecs), so WebCodecs will only help you with transforming raw video data into compressed (encoded) video data and vice versa.

You might think "that's annoying", as if WebCodecs doesn't provide a complete solution, but keep in mind that muxing and other utilities are easily implemented as 3rd party libraries. What a library can't do is access hardware-accelerated video encoding or decoding without the browser's help, and hardware acceleration is exactly what WebCodecs is helps with.


<br/>

<small>Also, WebCodecs is a low-level API, don't expect hand-holding. Use MediaBunny if you want easy-mode.</small>

### Why compression is still helpful

When streaming video data, you don't even need muxing or a video file; the `EncodedVideoChunk` is useful by itself as-is. 



##### Sending raw video

Consider the following mock example of streaming video a canvas in one worker to another. Here we are rendering an animation in the source worker, sending raw `VideoFrame` objects to the the destination worker and then rendering the raw `VideoFrame` on the destination canvas.


<iframe src="/demo/encoded-chunk-throughput/raw-pipeline.html" width="800" height="350" frameBorder="0"  style="height: 380px;"
></iframe>

Here is the pseudocode for the two workers (full code [here](./tbd))

<Tabs>

  <TabItem label="Worker1">

  ```javascript

function render() {

    ctx.clearRect(canvas.width, canvas.height);
    sourceCtx.fillText(`Frame ${frameNumber}`, 20, height / 2);

    const videoFrame = new VideoFrame(sourceCanvas, {
      timestamp: frameNumber * (1e6 / frameRate)
    });
    self.postMessage(videoFrame, [videoFrame]);

    frameNumber++;
    requestAnimationFrame(render)
  }

```
  
  </TabItem>

  <TabItem label="Worker2">
    ```javascript

self.addEventListener('message', (e) => {
      ctx.drawImage(e.data, 0, 0);
      frame.close();
});
  ```
  </TabItem>
</Tabs>


When sending raw uncompressed 320x240 video, we are sending about 9000 kilobytes per second or 72 Megabits / second, which is around the same bitrate you'd expect for studio-quality 4K video used by professional editors, and about as fast as real-world fiber-optic connections can realistically handle. 



##### Sending compressed video

Let's take the same exact example, but now we encode the video chunks before sending it between workers.


<iframe src="/demo/encoded-chunk-throughput/encoded-pipeline.html" width="800" height="350" frameBorder="0"  style="height: 380px;"
></iframe>




Here is the pseudo code for the two workers (full code [here](./tbd)):

<Tabs>

  <TabItem label="Worker1">

  ```javascript

 const encoder = new VideoEncoder({
    output: (chunk, metadata) => {
      self.postMessage(chunk)
    },
    error: (e) => console.error('Encoder error:', e)
  });

function render() {
    ctx.clearRect(canvas.width, canvas.height);
    sourceCtx.fillText(`Frame ${frameNumber}`, 20, height / 2);

    const videoFrame = new VideoFrame(sourceCanvas, {
      timestamp: frameNumber * (1e6 / frameRate)
    });

    encoder.encode(videoFrame, { keyFrame: frameNumber % 60 === 0 });
    videoFrame.close();

    frameNumber++;
    requestAnimationFrame(render)
  }

```
  
  </TabItem>

  <TabItem label="Worker2">
```javascript
const decoder = new VideoDecoder({
    output: (frame) => {
        ctx.drawImage(frame, 0, 0);
        frame.close();
    },
    error: (e) => console.error('Decoder error:', e)
});

self.addEventListener('message', (e) => {
      decoder.decode(e.data)
});
  ```
  </TabItem>
</Tabs>


As you can see, encoding the video reduces the bandwidth by 100x (9000 kB/s vs 9 kB/s). 


In the real world, if you are actually streaming 1080p video, the encoded and raw streams would be ~30x bigger.



## Key Frames
-- Key Frames vs Delta Frames, order matters
-- Delta frames

