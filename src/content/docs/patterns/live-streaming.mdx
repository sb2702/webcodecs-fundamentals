---
title: Live Streaming with WebCodecs
description: Low-latency encoder pipelines
---

import { Tabs, TabItem } from '@astrojs/starlight/components';


There are many ways to stream video over the internet, and of all the ways to deal with video streaming in the browser (`<video>`, MSE, WebRTC), WebCodecs provides the lowest level control. 

Emerging technologies like [Media Over Quic](../../projects/moq.md) use WebCodecs to provide lower latency and higher scalability than with previous options.

Unlike a transcoding pipeline, where it's pretty clear cut what needs to be done, how you would build a video-streaming application depends entirely on what you are trying to do.

Here are just a few kinds of applications with some form of video streaming:
* An application to watch live sports broadcasts
* Recording software to stream your webcam to multiple social-media live-streaming platforms
* A webinar tool where a few hosts stream content to many attendees

Each would have a different architecture, and for each there might be multiple ways to accomplish the same thing, so the choice of WebCodecs vs MSE vs WebRTC etc.. becomes a design choice.

 To make this manageable, I'll focus on how to do the following with WebCodecs:

* Stream video from a browser to a browser (e.g. video conferencing)
* Stream video from a browser to a server (e.g. recording studio)
* Stream video from a server to a browser (e.g. live broadcast)

I'll then provide a quick overview of the alternatives (WebRTC, MSE) and include some real world case studies of streaming applications and their architectures, to help you decide if and where WebCodecs makes sense.

Because WebCodecs works with binary encoded video data, it's a lot easier to integrate with server media processing libraries like ffmpeg and gstreamer. 
I'll therefore assume you can do whatever prcessing you need based on your application's business logic with server media processing libraries, and I'll stick to how you'd stream video to/from the browser with WebCodecs.

## Data transfer

Raw video is too large to stream over a network, so in any streaming scenario we'll be working with encoded video and audio data. For WebCodecs specifically, we'll primarily be working with `EncodedVideoChunk` and `EncodedAudioChunk` objects.

Other browser APIs like `WebRTC`and `MSE` have data transfer built-in and application developers don't normally manage how individual video packets are sent over the network.

The strength and weakness of WebCodecs is that it is very low-level, so you absolutely can control how individual video packets are sent over the network, but then you have to figure out how to send invidual video packets over the network.


#### The requirements

Let's start with the example of sending a video stream from the browser to a server. Our `VideoEncoder` gives us `EncodedVideoChunk` objects, and an `EncodedVideoChunk` is just binary data with some meta data attached.

![](/assets/patterns/livestreaming/encoded-chunk-2.svg)

For a streaming, we'd need to send a bunch of these chunks, in real time, in order, over a network, in a bidirectional manner.

![](/assets/patterns/livestreaming/encoded-chunk-3.svg)


With generic data transfer, there are a number of ways we could accomplish this:


#### The do-it-yourself networking options

###### HTTP

You could theoretically expose an HTTP endpoint on your server and `POST` every frame as data. Here's a simplified example where metadata is sent as a header

<Tabs>

  <TabItem label="Client">


  ```typescript
const buffer = new Uint8Array(chunk.byteLength)
chunk.copyTo(buffer);

fetch('/upload', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/octet-stream',
      'X-Timestamp': chunk.timestamp.toString(),
      'X-Index': chunkIndex.toString(),
      'X-Keyframe': chunk.type === 'key' ? '1' : '0',
    },
    body: chunk.data,
});

```
  
  </TabItem>

  <TabItem label="Server">
```typescript
app.post('/upload', (req, res) => {
    const timestamp = parseInt(req.headers['x-timestamp']);
    const keyframe = req.headers['x-keyframe'] === '1';
    const chunkIndex = parseInt(req.headers['x-index']);
    const data = req.body;
    res.json({ ok: true });
});
```
  </TabItem>
</Tabs>

For streaming this is impractical, as you'd be sending dozens of http requests per second which is slow and error prone. There is also no way to send data back to the client. You could make http work if you just need to upload media in chunks without worrying about real-time, but there are also inherently more suitable options.


###### Web Sockets

Web Sockets enables you create a persistent connection with a server, and it enables bidirectional flows of data. Here you could come up with your own binary encoding scheme to fit metadata and chunk data together into a single binary buffer and send those between server and client.

<Tabs>


  <TabItem label="Client">


  ```typescript
const ws = new WebSocket('ws://localhost:3000/upload');

const encoder = new VideoEncoder({
    output: (chunk) => {
        const binaryData = <Uint8Array> customBinaryEncodingScheme(chunk);
        ws.send(binaryData);
    },
    error: (e)=>{} //error handling
 });


```
  
  </TabItem>

  <TabItem label="Custom Binary Scheme">
  ```typescript
// Just an example, this is not official or canonical but it would work
function customBinaryEncodingScheme(chunk: EncodedVideoChunk): Uint8Array {

      const metadata = {
        timestamp: chunk.timestamp,
        keyframe: chunk.type === 'key',
        size: chunk.data.byteLength,
      };
      
      // Format: [metadata JSON length (4 bytes)] [metadata JSON] [binary data]
      const metadataStr = JSON.stringify(metadata);
      const metadataBytes = new TextEncoder().encode(metadataStr);
      
      const frame = new ArrayBuffer(4 + metadataBytes.length + chunk.data.byteLength);
      const view = new DataView(frame);
      
      // Write metadata length as 32-bit integer
      view.setUint32(0, metadataBytes.length, true);
      
      // Write metadata
      new Uint8Array(frame, 4, metadataBytes.length).set(metadataBytes);
      
      // Write binary data
      return new Uint8Array(frame, 4 + metadataBytes.length).set(new Uint8Array(chunk.data)
};
```
  </TabItem>

  <TabItem label="Server">
```typescript
const express = require('express');
const WebSocket = require('ws');
const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

wss.on('connection', (ws) => {
 
  ws.on('message', (data) => {
       // data is a Buffer
       const chunk = parseCustomBinary(data);
  });

});


```
  </TabItem>
</Tabs>

If you are only sending data one way, this could work, but if you need to enable data from one browser to another, you'd need your server to concurrently handle multiple websocket sessions and set up your own routing system.

###### Web Transport

WebTransport is like a successor to WebSockets, with support being rolled out [[2](https://caniuse.com/webtransport)],  but it enables better peformance and uses the [Streams API](../../concepts/streams). WebTransport lets you write this as a pipeline, where the video frame source (e.g. a user webcam) gets piped through the encooder (a `TransformStream` wrapper) and piped to a writer, which then writes data in a stream-like fashion over the network.

 ```typescript
const transport = await WebTransport.connect('https://localhost:3000/upload');
const stream = await transport.createUnidirectionalStream();
const writer = stream.getWriter();

 //PseudoCode
frameSource.pipeThrough(videoEncoder).pipeTo(writer);
 ```

This is a practical option for unidirectional streams, though like WebSockets, if you need to enable data from one browser to another, youâ€™d need to set up your own routing system.

#### Media over Quic

[Media over Quic](../../projects/moq) is a new protocol specifically designed for this use case of facilitating delivery of WebCodecs and other low-level streaming data without the need for 'do-it-yourself' networking.

It works as a [pub-sub](https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern) system, where a *publisher* can publish a stream of data to a *relay*, and a *subscriber* can subscribe to streams of data from a *relay*.

![](/assets/patterns/livestreaming/media-over-quic.svg)

Unlike WebRTC servers (which are also relays) Media over Quic relays are content-agnostic and don't rely on 'session state', making it more scalable. You can self host a relay [[2](https://github.com/moq-dev/moq)], but several CDN providers also offer Media Over Quick relays [[3](https://blog.cloudflare.com/moq/)].




<Tabs>


  <TabItem label="Publisher">


  ```typescript
import * as Moq from "@moq/lite";

const connection = await Moq.connect("https://relay.moq.some-cdn.com");

const broadcast = new Moq.Broadcast();

connection.publish('my-broadcast', broadcast);

// Pull-mode, tracks are created when subscribers subscribe
const {track, priority} =  await broadcast.requested();

if(track.name ==='chat'){
    const group = track.appendGroup();
    group.writeString("Hello, MoQ!");
    group.close();
}


```
  
  </TabItem>

  <TabItem label="Subscriber">

```typescript

import * as Moq from "@moq/lite";

const connection = await Moq.connect("https://relay.moq.some-cdn.com");

// Subscribe to a broadcast
const broadcast = connection.consume("my-broadcast");

// Subscribe to a specific track
const track = await broadcast.subscribe("chat");

// Read data as it arrives
for (;;) {
	const group = await track.nextGroup();
	if (!group) break;

	for (;;) {
		const frame = await group.readString();
		if (!frame) break;
        console.log("Received:", frame);
    }
}
```
  </TabItem>
</Tabs>


Media over Quic greatly simplifies the networking aspect (you don't even need to host your own server) while also being performant (CDN relays scale better than any WebRTC server) and providing low-level control over how and when you send encoded video chunks.

This all makes it ideal for our use case of streaming encoded chunks, so that's what we'll use in the rest of our examples.  You are of course free to use any data transfer mechanism you see fit, that is one of the benefits of WebCodecs.

You can find out more about Media over Quic [here](../../projects/moq), it's worth a read in general but for now it's time to get to code.

## Examples

### Browser to Browser

-- Production gotchas




### Server to browser

-- Production gotchas





### Browser to Server

-- parsing the data locally

-- Saving it locally

-- Production gotchas


## Alternatives

#### WebRTC

#### Media Source Extensions